import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

BASE_URL = 'https://www.mk.co.kr'
TARGET_URL = 'https://www.mk.co.kr/news/economy/'
HEADERS = {'User-Agent': 'Mozilla/5.0'}

# ë©”ì¸ í˜ì´ì§€ ìš”ì²­
res = requests.get(TARGET_URL, headers=HEADERS)
soup = BeautifulSoup(res.text, 'html.parser')

# ë‰´ìŠ¤ ì„¹ì…˜ ê°€ì ¸ì˜¤ê¸°
articles_section = soup.select_one('section.news_sec.best_view_news_sec')
news_items = articles_section.select('li.news_node a.news_item')

results = []

for item in news_items:
    try:
        # ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
        title = item.select_one('h3.news_ttl').text.strip()
        link = urljoin(BASE_URL, item['href'])

        # ê°œë³„ ê¸°ì‚¬ ìš”ì²­
        article_res = requests.get(link, headers=HEADERS)
        article_soup = BeautifulSoup(article_res.text, 'html.parser')

        # ë³¸ë¬¸ ì¶”ì¶œ (ì—¬ëŸ¬ êµ¬ì¡° ì¤‘ í•˜ë‚˜ ì„ íƒ)
        content_tag = (
            article_soup.select_one('div#article_body') or
            article_soup.select_one('div.art_txt')
        )

        if content_tag:
            content_text = content_tag.get_text(separator=' ', strip=True)
            content = content_text[:200] + '...' if len(content_text) > 200 else content_text
        else:
            content = 'ë³¸ë¬¸ ì—†ìŒ'

        # ì´ë¯¸ì§€ ì¶”ì¶œ (1. ë³¸ë¬¸ ë‚´ img  2. og:image)
        img_tag = content_tag.select_one('img') if content_tag else None
        if img_tag and img_tag.has_attr('src'):
            img_url = urljoin(BASE_URL, img_tag['src'])
        else:
            og_img_tag = article_soup.select_one('meta[property="og:image"]')
            img_url = og_img_tag['content'] if og_img_tag and og_img_tag.has_attr('content') else 'ì´ë¯¸ì§€ ì—†ìŒ'

        # ê²°ê³¼ ì €ì¥
        results.append({
            'title': title,
            'link': link,
            'content': content,
            'image': img_url
        })

    except Exception as e:
        print(f"[âŒ ì˜¤ë¥˜ ë°œìƒ] {item.get('href', 'ë§í¬ ì—†ìŒ')} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ê²°ê³¼ ì¶œë ¥
for idx, article in enumerate(results, start=1):
    print(f"[{idx}] {article['title']}")
    print(f"ğŸ”— ë§í¬: {article['link']}")
    print(f"ğŸ“ ë³¸ë¬¸: {article['content']}")
    print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€: {article['image']}")
    print('-' * 80)
